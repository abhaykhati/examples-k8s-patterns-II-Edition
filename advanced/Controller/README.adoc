== Controller

This example demonstrates a simple controller which evaluates `ConfigMaps` and restart associated pods if such a `ConfigMap` changes.

This controller is been inspired from https://github.com/fabric8io/configmapcontroller[configmap-controller] but for more limited.

This controller watches all `ConfigMap` in the namespace in which this controller is deployed and reacts on the annotation `k8spatterns.io/podDeleteSelector`.
If this annotation is given on a `ConfigMap` that has changed, then the value of this annotation is taken as a label selector to find `Pods` to kill.
Supposed that these pods are managed by a backend controller like `Deployment`, these `Pods` will be respawned again, eventually picking up the changed configuration.

For a full explanation of how this controller works, please refer to the "Controller" pattern in our book.

WARNING: Note, that this is example is meant for educational purposes only and is not suitable for general purpose usage.

The easiest way to try this example is by using https://github.com/kubernetes/minikube[minikube] with an ingress controller enabled:

[source,bash]
----
# Start minikube and enable the ingress addon
minikube start
minikube addons enable ingress
----

More options for running the example are described in link:../../INSTALL.adoc#minikube[installation instructions].

The controller script itself is stored in a `ConfigMap` and can be easily edited later on:

[source,bash]
----
kubectl create configmap config-watcher-controller --from-file=./config-watcher-controller.sh
----

In order to deploy the controller a `Deployment` creates a pod with two containers:

* One Kubernetes API proxy which exposes the Kubernetes API on localhost with port 8001. The image for `k8spatterns/kubeapi-proxy` is defined in this link:../images/kubeapi-proxy.dockerfile[Dockerfile].
* The main container which executes the script from the configmap. It is based on a single Alpine base image with https://curl.haxx.se/[curl] and https://stedolan.github.io/jq/[jq] included. The Dockerfile for this image `k8spattern/curl-jq` can be found link:../images/curl-jq.dockerfile[here].

Both images, https://cloud.docker.com/u/k8spatterns/repository/docker/k8spatterns/kubeapi-proxy[k8spatterns/kubeapi-proxy] and https://cloud.docker.com/u/k8spatterns/repository/docker/k8spatterns/curl-jq[k8spatterns/curl-jq] are available from Docker Hub.

To create this deployment in the current namespace, call:

[source,bash]
----
kubectl apply -f https://k8spatterns.io/Controller/config-watcher-controller.yml
----

You might want to have a look at the descriptor file; it contains some useful comments along the way and also the security setup to allow the controller to watch resources and to restart `Pods`.

That's all.
Now you have a nice little Controller which watches on `ConfigMap` and restart `Pods` in case of updates.

To try it out, we are reusing the super simple web application which just exposes an environment variable as content.
This link:../images/mini-http-server.dockerfile[image] uses `nc` to deliver the content and can be found on Docker Hub as https://cloud.docker.com/u/k8spatterns/repository/docker/k8spatterns/mini-http-server[k8spatterns/mini-http-server].

Before we deploy this app, we should tail on the log of our controller (e.g. `kubectl logs -f config-watcher-controller-....`) to see the events received by the controller as they come in, e.g. with

[source,bash]
----
kubectl logs -f $(kubectl get pods -l role=controller -o name) config-watcher
----

Then create the web application itself:

[source,bash]
----
kubectl apply -f https://k8spatterns.io/Controller/web-app.yml
----

If you look into this descriptor, you will find a `Deployment` using our dumb HTTP server which references the content environment variable via a `ConfigMap`.
The `ConfigMap` itself is annotated with a pod selector `k8spatterns.io/podDeleteSelector: "app=webapp"` which directly select the webapp `Pod`.

This resource file also includes the definition of a Service and an Ingress object so that we can access the server from the outside.

Before accessing the web-app we need to path the Ingress object to point to our minikube installation:

[source, bash]
----
kubectl patch ingress webapp --type=json \
   -p "[{op: replace, \
         path: /spec/rules/0/host, \
         value: webapp.$(minikube ip).nip.io}]"
----

NOTE: `nip.io` is a nice DNS reflector service, that as result of a DNS lookup just returns the IP address that is added before as subdomain just before the `.nip.io` part.

You can access our web app directly

[source,bash]
----
curl -sk https://webapp.$(minikube ip).nip.io
----

Now change the content of `ConfigMap` and watch the log of your controller:

[source,bash]
----
kubectl patch configmap webapp-config \
    -p '{"data":{"message":"Take this update!"}}'
----

and then finally call the URL again to check that the content has been updated to

[source,bash]
----
curl -sk https://webapp.$(minikube ip).nip.io
----

=== More Information

* https://oreil.ly/qQcZM[Controller Example]
* https://oreil.ly/3yuBU[Writing Controllers]
* https://oreil.ly/mY5Dc[Writing a Kubernetes Controller]
* https://oreil.ly/Qa2X4[A Deep Dive into Kubernetes Controllers]
* https://oreil.ly/Mq3GN[Expose Controller]
* https://oreil.ly/bcTYK[Reloader: ConfigMap Controller]
* https://oreil.ly/yZdL3[Writing a Custom Controller: Extending the Functionality of Your Cluster]
* https://oreil.ly/0zM5X[Writing Kubernetes Custom Controllers]
* https://oreil.ly/19xfy[Contour Ingress Controller]
* https://oreil.ly/FTxze[Syntax and Character Set]
* https://oreil.ly/_g75A[Kubectl-Proxy]
